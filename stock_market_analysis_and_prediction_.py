# -*- coding: utf-8 -*-
"""stock_market_analysis_and_prediction_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10_mY88qRlFXGiSxhrf0M8eleALSIyBKD

# **DATA LOADING**
"""

import pandas as pd
import matplotlib.pyplot as plt# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import zipfile
import os
from sklearn.preprocessing import LabelEncoder

# Provide the correct file path for your ZIP file
zip_file_path = "/content/stock price dataset.zip"

# Provide the directory where you want to extract the files
extract_to_directory = "/content/extracted_dataset/"

# Create the directory if it doesn't exist
os.makedirs(extract_to_directory, exist_ok=True)

# Unzip the dataset
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to_directory)

print("Dataset has been successfully extracted to:", extract_to_directory)

df=pd.read_csv("/content/extracted_dataset/all_stocks_5yr.csv")

df.head()

"""# **DATA PREPROCESSING AND EXPLORATORY DATA ANALYSIS**

DATASET INFO
"""

# Display basic information about the dataset
print("\nDataset Information:")
df.info()

"""TOTAL NULLS PER COLUMN"""

# Check for missing values
print("\nMissing values in the dataset:")
df.isnull().sum()

"""STATISTICAL DISTRIBUTION"""

# Display descriptive statistics
print("\nDescriptive Statistics:")
df.describe()

df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

"""DISTRIBUTION OF OPEN, HIGH, LOW AND CLOSE PRICES"""

# Distribution of open, high, low, close prices
plt.figure(figsize=(12, 8))
for i, col in enumerate(['open', 'high', 'low', 'close']):
    plt.subplot(2, 2, i+1)
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col.capitalize()} Prices')
plt.tight_layout()
plt.show()

"""BOXPLOTS FOR OPEN, HIGH, LOW AND CLOSE PRICES"""

# Boxplot of open, high, low, close prices
plt.figure(figsize=(12, 4))
sns.boxplot(data=df[['open', 'high', 'low', 'close']])
plt.title('Boxplot of Open, High, Low, Close Prices')
plt.show()

"""TIME SERISE ANALYSIS"""

# Time series analysis
# Set date as index
df.set_index('date', inplace=True)

# Line plot for open, high, low, close prices
plt.figure(figsize=(14, 8))
df[['open', 'high', 'low', 'close']].plot()
plt.title('Stock Prices Over Time')
plt.ylabel('Price in USD')
plt.xlabel('Date')
plt.show()

"""ANALYSIS OF MOVING AVERAGES"""

# Moving averages
df['MA30'] = df['close'].rolling(window=30).mean()
df['MA90'] = df['close'].rolling(window=90).mean()

plt.figure(figsize=(14, 8))
df['close'].plot(label='Close')
df['MA30'].plot(label='30 Day Moving Average')
df['MA90'].plot(label='90 Day Moving Average')
plt.title('Stock Prices with Moving Averages')
plt.ylabel('Price in USD')
plt.xlabel('Date')
plt.legend()
plt.show()

# Monthly average price
df['Month'] = df.index.month
monthly_avg = df.groupby('Month')['close'].mean()

plt.figure(figsize=(10, 4))
sns.barplot(x=monthly_avg.index, y=monthly_avg.values)
plt.title('Average Monthly Close Prices')
plt.xlabel('Month')
plt.ylabel('Average Close Price in USD')
plt.show()

"""VOLUMN ANALYSIS"""

# Volume analysis
plt.figure(figsize=(14, 6))
df['volume'].plot()
plt.title('Trading Volume Over Time')
plt.ylabel('Volume')
plt.xlabel('Date')
plt.show()

"""CORRELATION MATRIX"""

# Correlation matrix
plt.figure(figsize=(10, 6))
sns.heatmap(df[['open', 'high', 'low', 'close', 'volume']].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""# **DATA PREPROCESSING**

REMOVAL OF MISSING VALUES
"""

# Remove rows with any null values
df= df.dropna()

# Check for missing values
print("\nMissing values in the dataset:")
df.isnull().sum()

"""CONVERT NUMERICAL COLUMNS TO NUMERIC DATATYPE"""

# Convert numerical columns to numeric type
numeric_columns = ['open', 'high', 'low', 'close', 'volume']
df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric)

df.dtypes

"""FEATURE ENGINEERING (NEW COLUMN I.E DAILY RANGE)"""

# Feature engineering: Example - Calculate daily range
df['range'] = df['high'] - df['low']

df.head()

"""LABEL ENCODING OF COLUMN "Name"
"""

# Label encode the 'Name' column
label_encoder = LabelEncoder()
df['Name'] = label_encoder.fit_transform(df['Name'])

df.head()

"""# **PREPARATION OF DATASET FOR TRAINING**

CHOSING FEATURES AND TARGET LABEL
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Assuming df is your dataframe
# Define the features and target variable if you have a target column
# For instance, if 'confidence' is your target variable:
X = df.drop(columns=['close'])
y = df['close']

"""SPLITING THE DATASET INTO TRAINING AND TESTING"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# If you do not have a target variable and want to split the whole dataframe
# df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)

# Display the shape of the train and test sets
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

"""# **1) APPLYING LSTM WITH ATTENTION MECHANISM**"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Attention, Add
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Assuming X_train, X_test, y_train, y_test are already defined
# Normalize the features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshape input to be 3D [samples, timesteps, features] for LSTM
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# Define the LSTM with Attention model
inputs = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))
lstm_out = LSTM(50, return_sequences=True)(inputs)
attention = Attention()([lstm_out, lstm_out])
context_vector = tf.reduce_sum(attention, axis=1)
output = Dense(1)(context_vector)

model = tf.keras.Model(inputs=inputs, outputs=output)
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, validation_data=(X_test_reshaped, y_test), verbose=2, shuffle=False)

"""EVALUATION METRICES"""

# Evaluate the model
mse = model.evaluate(X_test_reshaped, y_test, verbose=0)
# Make predictions
y_pred = model.predict(X_test_reshaped)

# Calculate evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
nse = 1 - (np.sum((y_test - y_pred.flatten())**2) / np.sum((y_test - np.mean(y_test))**2))

print(f'R-squared value on test set: {r2}')
print(f'Mean Absolute Error on test set: {mae}')
print(f'Mean Squared Error on test set: {mse}')
print(f'Nash-Sutcliffe Efficiency on test set: {nse}')

"""TRAINING AND TESTING GRAPH"""

# Plot training and validation loss values, skipping the first epoch
plt.figure(figsize=(12, 5))
plt.plot(history.history['loss'][1:], label='Train Loss')
plt.plot(history.history['val_loss'][1:], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""EVALUATION GRAPHS"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Assuming dates is a pandas Series or array containing the dates for the test set
dates = X_test.index  # or any other way you have to get the dates for the test set

# Combine dates, y_test, and y_pred into a DataFrame for easy sorting
df = pd.DataFrame({'Date': dates, 'Actual': y_test, 'Predicted': y_pred.flatten()})

# Sort the DataFrame by date
df_sorted = df.sort_values(by='Date')

# Calculate R-squared value
r2 = r2_score(df_sorted['Actual'], df_sorted['Predicted'])
print(f'R-squared value on test set: {r2}')

# Plot actual vs predicted values
plt.figure(figsize=(28, 7))
plt.plot(df_sorted['Date'], df_sorted['Actual'], label='Actual')
plt.plot(df_sorted['Date'], df_sorted['Predicted'], label='Predicted')
plt.title('Actual vs Predicted Values')
plt.xlabel('Date')
plt.ylabel('Values of Close')
plt.legend()
plt.show()

"""**2) APPLYING LSTM-CNN MODEL**"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Dense, Input
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Normalize the features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshape input to be 3D [samples, timesteps, features] for LSTM
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# Define the LSTM + CNN model
inputs = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))

# CNN layers
cnn_out = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)
cnn_out = MaxPooling1D(pool_size=1)(cnn_out)

# LSTM layer
lstm_out = LSTM(50, activation='relu', return_sequences=False)(cnn_out)

# Output layer
output = Dense(1)(lstm_out)

model = tf.keras.Model(inputs=inputs, outputs=output)
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, validation_data=(X_test_reshaped, y_test), verbose=2, shuffle=False)

"""EVALUATION METRICES"""

# Evaluate the model
mse = model.evaluate(X_test_reshaped, y_test, verbose=0)
# Make predictions
y_pred = model.predict(X_test_reshaped)

# Calculate evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
nse = 1 - (np.sum((y_test - y_pred.flatten())**2) / np.sum((y_test - np.mean(y_test))**2))

print(f'R-squared value on test set: {r2}')
print(f'Mean Absolute Error on test set: {mae}')
print(f'Mean Squared Error on test set: {mse}')
print(f'Nash-Sutcliffe Efficiency on test set: {nse}')

"""TRAINING AND TESTING GRAPH"""

# Plot training and validation loss values, skipping the first epoch
plt.figure(figsize=(12, 5))
plt.plot(history.history['loss'][1:], label='Train Loss')
plt.plot(history.history['val_loss'][1:], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""EVALUATION GRAPHS"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Assuming dates is a pandas Series or array containing the dates for the test set
dates = X_test.index  # or any other way you have to get the dates for the test set

# Combine dates, y_test, and y_pred into a DataFrame for easy sorting
df = pd.DataFrame({'Date': dates, 'Actual': y_test, 'Predicted': y_pred.flatten()})

# Sort the DataFrame by date
df_sorted = df.sort_values(by='Date')

# Calculate R-squared value
r2 = r2_score(df_sorted['Actual'], df_sorted['Predicted'])
print(f'R-squared value on test set: {r2}')

# Plot actual vs predicted values
plt.figure(figsize=(28, 7))
plt.plot(df_sorted['Date'], df_sorted['Actual'], label='Actual')
plt.plot(df_sorted['Date'], df_sorted['Predicted'], label='Predicted')
plt.title('Actual vs Predicted Values')
plt.xlabel('Date')
plt.ylabel('Values of Close')
plt.legend()
plt.show()

"""**3) APPLYING BIDIRECTIONAL LSTM MODEL**"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Dense, Input, Bidirectional
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Normalize the features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshape input to be 3D [samples, timesteps, features] for LSTM
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# Define the CNN + Bidirectional LSTM model
inputs = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))

# CNN layers
cnn_out = Conv1D(filters=64, kernel_size=1, activation='relu')(inputs)
cnn_out = MaxPooling1D(pool_size=1)(cnn_out)

# Bidirectional LSTM layer
lstm_out = Bidirectional(LSTM(50, activation='relu', return_sequences=False))(cnn_out)

# Output layer
output = Dense(1)(lstm_out)

model = Model(inputs=inputs, outputs=output)
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, validation_data=(X_test_reshaped, y_test), verbose=2, shuffle=False)

"""EVALUATION METRICES"""

# Evaluate the model
mse = model.evaluate(X_test_reshaped, y_test, verbose=0)
# Make predictions
y_pred = model.predict(X_test_reshaped)

# Calculate evaluation metrics
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
nse = 1 - (np.sum((y_test - y_pred.flatten())**2) / np.sum((y_test - np.mean(y_test))**2))

print(f'R-squared value on test set: {r2}')
print(f'Mean Absolute Error on test set: {mae}')
print(f'Mean Squared Error on test set: {mse}')
print(f'Nash-Sutcliffe Efficiency on test set: {nse}')

"""TRAINING AND TESTING GRAPH"""

# Plot training and validation loss values, skipping the first epoch
plt.figure(figsize=(12, 5))
plt.plot(history.history['loss'][1:], label='Train Loss')
plt.plot(history.history['val_loss'][1:], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""EVALUATION GRAPHS"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Assuming dates is a pandas Series or array containing the dates for the test set
dates = X_test.index  # or any other way you have to get the dates for the test set

# Combine dates, y_test, and y_pred into a DataFrame for easy sorting
df = pd.DataFrame({'Date': dates, 'Actual': y_test, 'Predicted': y_pred.flatten()})

# Sort the DataFrame by date
df_sorted = df.sort_values(by='Date')

# Calculate R-squared value
r2 = r2_score(df_sorted['Actual'], df_sorted['Predicted'])
print(f'R-squared value on test set: {r2}')

# Plot actual vs predicted values
plt.figure(figsize=(28, 7))
plt.plot(df_sorted['Date'], df_sorted['Actual'], label='Actual')
plt.plot(df_sorted['Date'], df_sorted['Predicted'], label='Predicted')
plt.title('Actual vs Predicted Values')
plt.xlabel('Date')
plt.ylabel('Values of Close')
plt.legend()
plt.show()

